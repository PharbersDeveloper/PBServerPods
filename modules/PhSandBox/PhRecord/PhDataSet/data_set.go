// Code generated by github.com/actgardner/gogen-avro. DO NOT EDIT.
/*
 * SOURCE:
 *     DataSet.avsc
 */

package PhDataSet

import (
	"github.com/actgardner/gogen-avro/compiler"
	"github.com/actgardner/gogen-avro/container"
	"github.com/actgardner/gogen-avro/vm"
	"github.com/actgardner/gogen-avro/vm/types"
	"io"
)

type DataSet struct {
	ParentIds      []string
	MongoId        string
	JobContainerId string
	ColName        []string
	TabName        string
	Length         int32
	Url            string
	Description    string
}

func NewDataSetWriter(writer io.Writer, codec container.Codec, recordsPerBlock int64) (*container.Writer, error) {
	str := &DataSet{}
	return container.NewWriter(writer, codec, recordsPerBlock, str.Schema())
}

func DeserializeDataSet(r io.Reader) (*DataSet, error) {
	t := NewDataSet()
	err := deserializeField(r, t.Schema(), t.Schema(), t)
	return t, err
}

func DeserializeDataSetFromSchema(r io.Reader, schema string) (*DataSet, error) {
	t := NewDataSet()
	err := deserializeField(r, schema, t.Schema(), t)
	return t, err
}

func NewDataSet() *DataSet {
	return &DataSet{}
}

func (r *DataSet) Schema() string {
	return "{\"fields\":[{\"name\":\"parentIds\",\"type\":{\"items\":\"string\",\"type\":\"array\"}},{\"name\":\"mongoId\",\"type\":\"string\"},{\"name\":\"jobContainerId\",\"type\":\"string\"},{\"name\":\"colName\",\"type\":{\"items\":\"string\",\"type\":\"array\"}},{\"name\":\"tabName\",\"type\":\"string\"},{\"name\":\"length\",\"type\":\"int\"},{\"name\":\"url\",\"type\":\"string\"},{\"name\":\"description\",\"type\":\"string\"}],\"name\":\"DataSet\",\"namespace\":\"com.pharbers.kafka.schema\",\"type\":\"record\"}"
}

func (r *DataSet) SchemaName() string {
	return "com.pharbers.kafka.schema.DataSet"
}

func (r *DataSet) Serialize(w io.Writer) error {
	return writeDataSet(r, w)
}

func (_ *DataSet) SetBoolean(v bool)    { panic("Unsupported operation") }
func (_ *DataSet) SetInt(v int32)       { panic("Unsupported operation") }
func (_ *DataSet) SetLong(v int64)      { panic("Unsupported operation") }
func (_ *DataSet) SetFloat(v float32)   { panic("Unsupported operation") }
func (_ *DataSet) SetDouble(v float64)  { panic("Unsupported operation") }
func (_ *DataSet) SetBytes(v []byte)    { panic("Unsupported operation") }
func (_ *DataSet) SetString(v string)   { panic("Unsupported operation") }
func (_ *DataSet) SetUnionElem(v int64) { panic("Unsupported operation") }
func (r *DataSet) Get(i int) types.Field {
	switch i {
	case 0:
		r.ParentIds = make([]string, 0)
		return (*ArrayStringWrapper)(&r.ParentIds)
	case 1:
		return (*types.String)(&r.MongoId)
	case 2:
		return (*types.String)(&r.JobContainerId)
	case 3:
		r.ColName = make([]string, 0)
		return (*ArrayStringWrapper)(&r.ColName)
	case 4:
		return (*types.String)(&r.TabName)
	case 5:
		return (*types.Int)(&r.Length)
	case 6:
		return (*types.String)(&r.Url)
	case 7:
		return (*types.String)(&r.Description)

	}
	panic("Unknown field index")
}
func (r *DataSet) SetDefault(i int) {
	switch i {

	}
	panic("Unknown field index")
}
func (_ *DataSet) AppendMap(key string) types.Field { panic("Unsupported operation") }
func (_ *DataSet) AppendArray() types.Field         { panic("Unsupported operation") }
func (_ *DataSet) Finalize()                        {}

type DataSetReader struct {
	r io.Reader
	p *vm.Program
}

func NewDataSetReader(r io.Reader) (*DataSetReader, error) {
	containerReader, err := container.NewReader(r)
	if err != nil {
		return nil, err
	}

	t := NewDataSet()
	deser, err := compiler.CompileSchemaBytes([]byte(containerReader.AvroContainerSchema()), []byte(t.Schema()))
	if err != nil {
		return nil, err
	}

	return &DataSetReader{
		r: containerReader,
		p: deser,
	}, nil
}

func (r *DataSetReader) Read() (*DataSet, error) {
	t := NewDataSet()
	err := vm.Eval(r.r, r.p, t)
	return t, err
}
